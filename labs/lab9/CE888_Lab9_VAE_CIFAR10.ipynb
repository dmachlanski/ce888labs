{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE CelebA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Fs9L8OBezg7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6aa8a8c-75ed-4122-e368-3b08f770ff77"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ofVKkHh0660",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = (32, 32, 3, 1)\n",
        "batch_size = 16\n",
        "latent_dim = 2 # Dimensionality of the latent space: a 2D plane\n",
        "input_img = keras.Input(shape=img_shape)\n",
        "x = layers.Conv3D(32, 3, padding='same', activation='relu')(input_img)\n",
        "x = layers.Conv3D(64, 3, padding='same', activation='relu', strides=(2, 2, 1))(x)\n",
        "x = layers.Conv3D(64, 3, padding='same', activation='relu')(x)\n",
        "x = layers.Conv3D(64, 3, padding='same', activation='relu')(x)\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# The input image ends up being encoded into these two parameters\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6qqG5k709l8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Latent-space-sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlasfqFP0_kU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_input = layers.Input(K.int_shape(z)[1:]) # Input where youâ€™ll feed z\n",
        "\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]), \n",
        "                 activation='relu')(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "x = layers.Conv3DTranspose(32, 3,padding='same',\n",
        "                           activation='relu',strides=(2, 2, 1))(x)\n",
        "x = layers.Conv3D(1, 3,padding='same',activation='sigmoid')(x)\n",
        "decoder = Model(decoder_input, x)\n",
        "z_decoded = decoder(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTb7TPx51SFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "    \n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        kl_loss = -5e-4 * K.mean(\n",
        "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "    \n",
        "    #You implement custom layers You don't use by writing a call method.\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return x # You don't use this output, but the layer must return something.\n",
        "    \n",
        "y = CustomVariationalLayer()([input_img, z_decoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rG5Z7ZCq1UAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "a68cd173-9bc8-45b1-8915-03242b48d8e1"
      },
      "cell_type": "code",
      "source": [
        "#from keras.datasets import mnist\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()\n",
        "\n",
        "#(x_train, _), (x_test, y_test) = mnist.load_data()\n",
        "# 32x32 images\n",
        "(x_train, _), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "vae.fit(x=x_train, y=None, shuffle=True, epochs=10, \n",
        "        batch_size=batch_size, validation_data=(x_test, None))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 32, 32, 3, 32 896         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 16, 16, 3, 64 55360       conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 16, 16, 3, 64 110656      conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 16, 16, 3, 64 110656      conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 49152)        0           conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32)           1572896     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 2)            66          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            66          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 32, 32, 3, 1) 203649      lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_2 (Cus [(None, 32, 32, 3, 1 0           input_5[0][0]                    \n",
            "                                                                 model_3[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,054,245\n",
            "Trainable params: 2,054,245\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 185s 4ms/step - loss: 0.6448 - val_loss: 0.6376\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.6377 - val_loss: 0.6372\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 183s 4ms/step - loss: 0.6371 - val_loss: 0.6383\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.6368 - val_loss: 0.6383\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.6366 - val_loss: 0.6379\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.6363 - val_loss: 0.6369\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 183s 4ms/step - loss: 0.6361 - val_loss: 0.6363\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 183s 4ms/step - loss: 0.6359 - val_loss: 0.6364\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 182s 4ms/step - loss: 0.6358 - val_loss: 0.6361\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 180s 4ms/step - loss: 0.6356 - val_loss: 0.6362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f02ef187c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "o5v8Lnw81WB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a58bd05b-85ed-4a57-aa70-ceb3f7451ae8"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "n = 15\n",
        "digit_size = 32\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
        "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "            j * digit_size: (j + 1) * digit_size] = digit\n",
        "        \n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-db0aa599ca7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_decoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         figure[i * digit_size: (i + 1) * digit_size,\n\u001b[1;32m     15\u001b[0m             j * digit_size: (j + 1) * digit_size] = digit\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3072 into shape (32,32)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bxNrtU96SYB1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}